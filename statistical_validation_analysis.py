"""
============================================================
ë§¨ì¦ˆì¼€ì–´ ë°ì´ì•¤ë‚˜ì´íŠ¸ ë“€ì–¼ ìƒ´í‘¸ - í†µê³„ì  ì‹ ë¢°ì„± ê²€ì¦ ë¶„ì„
============================================================
Feature Importanceì˜ ì‹ ë¢°ì„±ì„ ê²€ì¦í•˜ê³  í•´ì„ì„ ì œê³µ

ë¶„ì„ ë‚´ìš©:
1. Logistic Regression p-value ê²€ì • (í†µê³„ì  ìœ ì˜ì„±)
2. Permutation Importance (ë” ì•ˆì •ì ì¸ ì¤‘ìš”ë„)
3. Bootstrap Confidence Interval (ì‹ ë¢°êµ¬ê°„)
4. ìƒê´€ê´€ê³„ ë¶„ì„ ë° ì¹´ì´ì œê³± ê²€ì •
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.inspection import permutation_importance
import statsmodels.api as sm
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv('í—¤ì–´Â·ë‘í”¼ ì¼€ì–´ ì œí’ˆì— ëŒ€í•œ ìˆ˜ìš” ì„¤ë¬¸ì¡°ì‚¬(ì‘ë‹µ) - ì„¤ë¬¸ì§€ ì‘ë‹µ ì‹œíŠ¸1.csv', skiprows=5, header=None)
df.columns = ['íƒ€ì„ìŠ¤íƒ¬í”„', 'ì„±ë³„', 'ì—°ë ¹ëŒ€', 'ë¨¸ë¦¬ê°ëŠ”ì‹œê°„', 'ë‘í”¼ê³ ë¯¼', 'ìƒ´í‘¸ì„ íƒì´ìœ ', 'ìƒ´í‘¸ì•„ì‰¬ìš´ì ', 'Q7', 'Q8', 'ê¸°íƒ€1', 'ê¸°íƒ€2']

print("=" * 70)
print("ğŸ”¬ í†µê³„ì  ì‹ ë¢°ì„± ê²€ì¦ ë¶„ì„")
print("=" * 70)
print("""
ì´ ë¶„ì„ì€ ì´ì „ Feature Importance ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
íŠ¹íˆ "Q7(ë‘í”¼ì°¨ì´ì¸ì‹)ì´ êµ¬ë§¤ ì˜í–¥ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤"ëŠ” 
ê²°ë¡ ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
""")

# ============================================================
# ë°ì´í„° ì „ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)
# ============================================================
df['êµ¬ë§¤ì˜í–¥'] = (df['Q8'] == 'ìˆë‹¤').astype(int)

le_gender = LabelEncoder()
le_age = LabelEncoder()
le_time = LabelEncoder()

df['ì„±ë³„_encoded'] = le_gender.fit_transform(df['ì„±ë³„'])
df['ì—°ë ¹ëŒ€_encoded'] = le_age.fit_transform(df['ì—°ë ¹ëŒ€'])
df['ë¨¸ë¦¬ê°ëŠ”ì‹œê°„_encoded'] = le_time.fit_transform(df['ë¨¸ë¦¬ê°ëŠ”ì‹œê°„'])
df['Q7_score'] = pd.to_numeric(df['Q7'], errors='coerce').fillna(3)
df['í•˜ë£¨2ë²ˆìƒ´í‘¸'] = df['ë¨¸ë¦¬ê°ëŠ”ì‹œê°„'].str.contains('ì•„ì¹¨&ì €ë…', na=False).astype(int)

scalp_concerns = ['ë‘í”¼ ì—´ê°', 'ìœ ë¶„ ê³¼ë‹¤', 'ê±´ì¡°í•¨', 'ê°€ë ¤ì›€', 'íƒˆëª¨', 'ë¯¼ê°ì„±', 'íŠ¹ë³„í•œ ê³ ë¯¼ ì—†ìŒ']
for concern in scalp_concerns:
    df[f'ê³ ë¯¼_{concern}'] = df['ë‘í”¼ê³ ë¯¼'].str.contains(concern, na=False).astype(int)

shampoo_reasons = ['ë‘í”¼ ì¼€ì–´', 'íƒˆëª¨ ì™„í™”', 'ì„¸ì •ë ¥', 'í–¥', 'ê°€ê²©', 'ë¸Œëœë“œ']
for reason in shampoo_reasons:
    df[f'ì´ìœ _{reason}'] = df['ìƒ´í‘¸ì„ íƒì´ìœ '].str.contains(reason, na=False).astype(int)

feature_names = ['ì„±ë³„_encoded', 'ì—°ë ¹ëŒ€_encoded', 'Q7_score', 'í•˜ë£¨2ë²ˆìƒ´í‘¸'] + \
                [f'ê³ ë¯¼_{c}' for c in scalp_concerns] + \
                [f'ì´ìœ _{r}' for r in shampoo_reasons]

feature_names_kr = ['ì„±ë³„', 'ì—°ë ¹ëŒ€', 'Q7(ë‘í”¼ì°¨ì´ì¸ì‹)', 'í•˜ë£¨2ë²ˆìƒ´í‘¸',
                    'ê³ ë¯¼:ë‘í”¼ì—´ê°', 'ê³ ë¯¼:ìœ ë¶„ê³¼ë‹¤', 'ê³ ë¯¼:ê±´ì¡°í•¨', 'ê³ ë¯¼:ê°€ë ¤ì›€', 
                    'ê³ ë¯¼:íƒˆëª¨', 'ê³ ë¯¼:ë¯¼ê°ì„±', 'ê³ ë¯¼:ì—†ìŒ',
                    'ì´ìœ :ë‘í”¼ì¼€ì–´', 'ì´ìœ :íƒˆëª¨ì™„í™”', 'ì´ìœ :ì„¸ì •ë ¥', 
                    'ì´ìœ :í–¥', 'ì´ìœ :ê°€ê²©', 'ì´ìœ :ë¸Œëœë“œ']

X = df[feature_names]
y = df['êµ¬ë§¤ì˜í–¥']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_scaled = scaler.fit_transform(X)

print(f"ğŸ“Š ë°ì´í„° ê°œìš”:")
print(f"   ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df)}ëª…")
print(f"   êµ¬ë§¤ ì˜í–¥ ìˆìŒ: {y.sum()}ëª… ({y.mean()*100:.1f}%)")
print(f"   êµ¬ë§¤ ì˜í–¥ ì—†ìŒ: {len(y) - y.sum()}ëª… ({(1-y.mean())*100:.1f}%)")

# ============================================================
# 1. Logistic Regression p-value ê²€ì • (statsmodels ì‚¬ìš©)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Œ 1. Logistic Regression í†µê³„ì  ìœ ì˜ì„± ê²€ì •")
print("=" * 70)

print("""
ğŸ“– í•´ì„ ê°€ì´ë“œ:
   â€¢ p-value < 0.05: í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•¨ (95% ì‹ ë¢°ìˆ˜ì¤€)
   â€¢ p-value < 0.01: ë§¤ìš° ìœ ì˜ë¯¸í•¨ (99% ì‹ ë¢°ìˆ˜ì¤€)
   â€¢ p-value < 0.001: ê·¹íˆ ìœ ì˜ë¯¸í•¨ (99.9% ì‹ ë¢°ìˆ˜ì¤€)
   â€¢ Odds Ratio > 1: í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í•˜ë©´ êµ¬ë§¤ ì˜í–¥ ì¦ê°€
   â€¢ Odds Ratio < 1: í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í•˜ë©´ êµ¬ë§¤ ì˜í–¥ ê°ì†Œ
""")

# statsmodelsë¡œ p-value ê³„ì‚°
X_with_const = sm.add_constant(X_scaled)
logit_model = sm.Logit(y, X_with_const)
result = logit_model.fit(disp=0)

# ê²°ê³¼ ì •ë¦¬
stats_df = pd.DataFrame({
    'í”¼ì²˜': ['ìƒìˆ˜'] + feature_names_kr,
    'ê³„ìˆ˜': result.params,
    'í‘œì¤€ì˜¤ì°¨': result.bse,
    'zê°’': result.tvalues,
    'p-value': result.pvalues,
    'Odds Ratio': np.exp(result.params)
})

# ìœ ì˜ì„± í‘œì‹œ
def significance_stars(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

stats_df['ìœ ì˜ì„±'] = stats_df['p-value'].apply(significance_stars)
stats_df = stats_df[stats_df['í”¼ì²˜'] != 'ìƒìˆ˜']  # ìƒìˆ˜ ì œì™¸
stats_df_sorted = stats_df.sort_values('p-value')

print("\nğŸ“Š Logistic Regression ê²°ê³¼ (p-value ìˆœ):")
print("-" * 85)
print(f"{'í”¼ì²˜':<20} {'ê³„ìˆ˜':>10} {'Odds Ratio':>12} {'p-value':>12} {'ìœ ì˜ì„±':>6}")
print("-" * 85)

for _, row in stats_df_sorted.iterrows():
    sig_mark = row['ìœ ì˜ì„±']
    p_str = f"{row['p-value']:.4f}" if row['p-value'] >= 0.0001 else "<0.0001"
    print(f"{row['í”¼ì²˜']:<20} {row['ê³„ìˆ˜']:>+10.4f} {row['Odds Ratio']:>12.4f} {p_str:>12} {sig_mark:>6}")

print("-" * 85)
print("ìœ ì˜ìˆ˜ì¤€: *** p<0.001, ** p<0.01, * p<0.05, . p<0.1")

# Q7 ê²°ê³¼ ê°•ì¡°
q7_row = stats_df[stats_df['í”¼ì²˜'] == 'Q7(ë‘í”¼ì°¨ì´ì¸ì‹)'].iloc[0]
print(f"\nğŸ’¡ Q7(ë‘í”¼ì°¨ì´ì¸ì‹) ìƒì„¸ í•´ì„:")
print(f"   â€¢ ê³„ìˆ˜: {q7_row['ê³„ìˆ˜']:+.4f}")
print(f"   â€¢ p-value: {q7_row['p-value']:.4f}")
print(f"   â€¢ Odds Ratio: {q7_row['Odds Ratio']:.4f}")

if q7_row['p-value'] < 0.05:
    print(f"\n   âœ… ê²°ë¡ : Q7ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•©ë‹ˆë‹¤ (p < 0.05)")
    print(f"   ğŸ“Š Odds Ratio {q7_row['Odds Ratio']:.2f}ì˜ ì˜ë¯¸:")
    print(f"      Q7 ì ìˆ˜ê°€ 1ì  ì¦ê°€í•  ë•Œë§ˆë‹¤ êµ¬ë§¤ ì˜í–¥ì´")
    print(f"      {(q7_row['Odds Ratio']-1)*100:.1f}% ì¦ê°€í•©ë‹ˆë‹¤.")
else:
    print(f"\n   âš ï¸ ì£¼ì˜: Q7ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (p >= 0.05)")
    print(f"      ìƒ˜í”Œ ìˆ˜ê°€ ì ì–´ í†µê³„ì  ê²€ì •ë ¥ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ ìš”ì•½
significant_vars = stats_df[stats_df['p-value'] < 0.05]
marginally_significant = stats_df[(stats_df['p-value'] >= 0.05) & (stats_df['p-value'] < 0.1)]

print(f"\nğŸ“Š í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ (p < 0.05): {len(significant_vars)}ê°œ")
for _, row in significant_vars.iterrows():
    direction = "â†‘ êµ¬ë§¤ì˜í–¥ ì¦ê°€" if row['ê³„ìˆ˜'] > 0 else "â†“ êµ¬ë§¤ì˜í–¥ ê°ì†Œ"
    print(f"   â€¢ {row['í”¼ì²˜']}: {direction} (p={row['p-value']:.4f})")

if len(marginally_significant) > 0:
    print(f"\nğŸ“Š ê²½ê³„ì„ ìƒ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ (0.05 â‰¤ p < 0.1): {len(marginally_significant)}ê°œ")
    for _, row in marginally_significant.iterrows():
        direction = "â†‘" if row['ê³„ìˆ˜'] > 0 else "â†“"
        print(f"   â€¢ {row['í”¼ì²˜']}: {direction} (p={row['p-value']:.4f})")

# ============================================================
# 2. Permutation Importance (ë” ì•ˆì •ì ì¸ ì¤‘ìš”ë„ ì¸¡ì •)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Œ 2. Permutation Importance ë¶„ì„")
print("=" * 70)

print("""
ğŸ“– í•´ì„ ê°€ì´ë“œ:
   Permutation ImportanceëŠ” ê° í”¼ì²˜ì˜ ê°’ì„ ë¬´ì‘ìœ„ë¡œ ì„ì—ˆì„ ë•Œ
   ëª¨ë¸ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜ ë–¨ì–´ì§€ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
   
   â€¢ ì„±ëŠ¥ í•˜ë½ì´ í¬ë©´: í•´ë‹¹ í”¼ì²˜ê°€ ì¤‘ìš”í•¨
   â€¢ ì„±ëŠ¥ í•˜ë½ì´ ì‘ìœ¼ë©´: í•´ë‹¹ í”¼ì²˜ê°€ ëœ ì¤‘ìš”í•¨
   â€¢ í‘œì¤€í¸ì°¨ê°€ ì‘ìœ¼ë©´: ê²°ê³¼ê°€ ì•ˆì •ì ì„
""")

# Random Forestë¡œ Permutation Importance ê³„ì‚°
rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf_model.fit(X_train, y_train)

# Permutation Importance (10ë²ˆ ë°˜ë³µ)
perm_importance = permutation_importance(rf_model, X_test, y_test, n_repeats=30, random_state=42)

perm_df = pd.DataFrame({
    'í”¼ì²˜': feature_names_kr,
    'ì¤‘ìš”ë„': perm_importance.importances_mean,
    'í‘œì¤€í¸ì°¨': perm_importance.importances_std
}).sort_values('ì¤‘ìš”ë„', ascending=False)

print("\nğŸ“Š Permutation Importance (Top 10):")
print("-" * 60)
print(f"{'í”¼ì²˜':<25} {'ì¤‘ìš”ë„':>12} {'í‘œì¤€í¸ì°¨':>12} {'ì‹ ë¢°êµ¬ê°„':<20}")
print("-" * 60)

for _, row in perm_df.head(10).iterrows():
    ci_low = row['ì¤‘ìš”ë„'] - 1.96 * row['í‘œì¤€í¸ì°¨']
    ci_high = row['ì¤‘ìš”ë„'] + 1.96 * row['í‘œì¤€í¸ì°¨']
    ci_str = f"[{ci_low:.4f}, {ci_high:.4f}]"
    print(f"{row['í”¼ì²˜']:<25} {row['ì¤‘ìš”ë„']:>12.4f} {row['í‘œì¤€í¸ì°¨']:>12.4f} {ci_str:<20}")

# Q7 Permutation Importance í•´ì„
q7_perm = perm_df[perm_df['í”¼ì²˜'] == 'Q7(ë‘í”¼ì°¨ì´ì¸ì‹)'].iloc[0]
q7_rank = perm_df[perm_df['í”¼ì²˜'] == 'Q7(ë‘í”¼ì°¨ì´ì¸ì‹)'].index[0] + 1

print(f"\nğŸ’¡ Q7(ë‘í”¼ì°¨ì´ì¸ì‹) Permutation Importance í•´ì„:")
print(f"   â€¢ ìˆœìœ„: {q7_rank}ìœ„")
print(f"   â€¢ ì¤‘ìš”ë„: {q7_perm['ì¤‘ìš”ë„']:.4f} Â± {q7_perm['í‘œì¤€í¸ì°¨']:.4f}")
print(f"   â€¢ 95% ì‹ ë¢°êµ¬ê°„: [{q7_perm['ì¤‘ìš”ë„'] - 1.96*q7_perm['í‘œì¤€í¸ì°¨']:.4f}, {q7_perm['ì¤‘ìš”ë„'] + 1.96*q7_perm['í‘œì¤€í¸ì°¨']:.4f}]")

if q7_perm['ì¤‘ìš”ë„'] - 1.96*q7_perm['í‘œì¤€í¸ì°¨'] > 0:
    print(f"   âœ… ì‹ ë¢°êµ¬ê°„ì´ 0ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ â†’ ì•ˆì •ì ìœ¼ë¡œ ì¤‘ìš”í•œ í”¼ì²˜")
else:
    print(f"   âš ï¸ ì‹ ë¢°êµ¬ê°„ì´ 0ì„ í¬í•¨ â†’ ì¤‘ìš”ë„ê°€ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ")

# ============================================================
# 3. Bootstrap Confidence Interval
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Œ 3. Bootstrap ì‹ ë¢°êµ¬ê°„ ë¶„ì„")
print("=" * 70)

print("""
ğŸ“– í•´ì„ ê°€ì´ë“œ:
   Bootstrapì€ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë²ˆ ì¬ìƒ˜í”Œë§í•˜ì—¬
   Feature Importanceì˜ ë¶„í¬ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.
   
   â€¢ 95% ì‹ ë¢°êµ¬ê°„ì´ ì¢ìœ¼ë©´: ê²°ê³¼ê°€ ì•ˆì •ì 
   â€¢ 95% ì‹ ë¢°êµ¬ê°„ì´ ë„“ìœ¼ë©´: ê²°ê³¼ê°€ ë¶ˆì•ˆì • (ìƒ˜í”Œ ìˆ˜ ë¶€ì¡± ê°€ëŠ¥)
""")

n_bootstrap = 100
bootstrap_importances = np.zeros((n_bootstrap, len(feature_names)))

print(f"\në¶€íŠ¸ìŠ¤íŠ¸ë© ë¶„ì„ ì¤‘... (n={n_bootstrap})")

for i in range(n_bootstrap):
    # ë³µì› ì¶”ì¶œë¡œ ìƒ˜í”Œë§
    indices = np.random.choice(len(X), size=len(X), replace=True)
    X_boot = X.iloc[indices]
    y_boot = y.iloc[indices]
    
    # ëª¨ë¸ í•™ìŠµ
    rf_boot = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=i)
    rf_boot.fit(X_boot, y_boot)
    bootstrap_importances[i] = rf_boot.feature_importances_

# ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
bootstrap_df = pd.DataFrame({
    'í”¼ì²˜': feature_names_kr,
    'í‰ê·  ì¤‘ìš”ë„': bootstrap_importances.mean(axis=0),
    'í‘œì¤€í¸ì°¨': bootstrap_importances.std(axis=0),
    '2.5% ë°±ë¶„ìœ„': np.percentile(bootstrap_importances, 2.5, axis=0),
    '97.5% ë°±ë¶„ìœ„': np.percentile(bootstrap_importances, 97.5, axis=0)
}).sort_values('í‰ê·  ì¤‘ìš”ë„', ascending=False)

print("\nğŸ“Š Bootstrap Feature Importance (95% ì‹ ë¢°êµ¬ê°„):")
print("-" * 75)
print(f"{'í”¼ì²˜':<25} {'í‰ê· ':>10} {'í‘œì¤€í¸ì°¨':>10} {'95% CI':<25}")
print("-" * 75)

for _, row in bootstrap_df.head(10).iterrows():
    ci_str = f"[{row['2.5% ë°±ë¶„ìœ„']:.4f}, {row['97.5% ë°±ë¶„ìœ„']:.4f}]"
    print(f"{row['í”¼ì²˜']:<25} {row['í‰ê·  ì¤‘ìš”ë„']:>10.4f} {row['í‘œì¤€í¸ì°¨']:>10.4f} {ci_str:<25}")

# Q7 Bootstrap ê²°ê³¼
q7_boot = bootstrap_df[bootstrap_df['í”¼ì²˜'] == 'Q7(ë‘í”¼ì°¨ì´ì¸ì‹)'].iloc[0]
print(f"\nğŸ’¡ Q7(ë‘í”¼ì°¨ì´ì¸ì‹) Bootstrap ë¶„ì„ ê²°ê³¼:")
print(f"   â€¢ í‰ê·  ì¤‘ìš”ë„: {q7_boot['í‰ê·  ì¤‘ìš”ë„']:.4f}")
print(f"   â€¢ 95% ì‹ ë¢°êµ¬ê°„: [{q7_boot['2.5% ë°±ë¶„ìœ„']:.4f}, {q7_boot['97.5% ë°±ë¶„ìœ„']:.4f}]")
print(f"   â€¢ ì‹ ë¢°êµ¬ê°„ í­: {q7_boot['97.5% ë°±ë¶„ìœ„'] - q7_boot['2.5% ë°±ë¶„ìœ„']:.4f}")

# ============================================================
# 4. ë‹¨ë³€ëŸ‰ ë¶„ì„ (Chi-square, T-test)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Œ 4. ë‹¨ë³€ëŸ‰ í†µê³„ ê²€ì •")
print("=" * 70)

print("""
ğŸ“– í•´ì„ ê°€ì´ë“œ:
   ê° ë³€ìˆ˜ì™€ êµ¬ë§¤ ì˜í–¥ ê°„ì˜ ê´€ê³„ë¥¼ ê°œë³„ì ìœ¼ë¡œ ê²€ì •í•©ë‹ˆë‹¤.
   
   â€¢ ì—°ì†í˜• ë³€ìˆ˜: T-test (ë‘ ê·¸ë£¹ í‰ê·  ë¹„êµ)
   â€¢ ë²”ì£¼í˜• ë³€ìˆ˜: Chi-square test (ë…ë¦½ì„± ê²€ì •)
""")

# Q7ê³¼ êµ¬ë§¤ ì˜í–¥: T-test
q7_purchase_yes = df[df['êµ¬ë§¤ì˜í–¥'] == 1]['Q7_score']
q7_purchase_no = df[df['êµ¬ë§¤ì˜í–¥'] == 0]['Q7_score']

t_stat, t_pvalue = stats.ttest_ind(q7_purchase_yes, q7_purchase_no)
cohens_d = (q7_purchase_yes.mean() - q7_purchase_no.mean()) / np.sqrt(
    ((len(q7_purchase_yes)-1)*q7_purchase_yes.std()**2 + (len(q7_purchase_no)-1)*q7_purchase_no.std()**2) / 
    (len(q7_purchase_yes) + len(q7_purchase_no) - 2)
)

print("\nğŸ“Š Q7(ë‘í”¼ì°¨ì´ì¸ì‹) vs êµ¬ë§¤ ì˜í–¥ - T-test:")
print("-" * 50)
print(f"   êµ¬ë§¤ ì˜í–¥ ìˆìŒ ê·¸ë£¹ Q7 í‰ê· : {q7_purchase_yes.mean():.2f} (n={len(q7_purchase_yes)})")
print(f"   êµ¬ë§¤ ì˜í–¥ ì—†ìŒ ê·¸ë£¹ Q7 í‰ê· : {q7_purchase_no.mean():.2f} (n={len(q7_purchase_no)})")
print(f"   í‰ê·  ì°¨ì´: {q7_purchase_yes.mean() - q7_purchase_no.mean():.2f}")
print(f"   t-í†µê³„ëŸ‰: {t_stat:.4f}")
print(f"   p-value: {t_pvalue:.4f}")
print(f"   Cohen's d (íš¨ê³¼ í¬ê¸°): {cohens_d:.4f}")

# íš¨ê³¼ í¬ê¸° í•´ì„
if abs(cohens_d) < 0.2:
    effect_size_interp = "ì‘ì€ íš¨ê³¼"
elif abs(cohens_d) < 0.5:
    effect_size_interp = "ì¤‘ê°„ íš¨ê³¼"
elif abs(cohens_d) < 0.8:
    effect_size_interp = "ì¤‘ê°„~í° íš¨ê³¼"
else:
    effect_size_interp = "í° íš¨ê³¼"

print(f"\nğŸ’¡ í•´ì„:")
if t_pvalue < 0.05:
    print(f"   âœ… í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤ (p = {t_pvalue:.4f} < 0.05)")
else:
    print(f"   âš ï¸ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤ (p = {t_pvalue:.4f} >= 0.05)")
print(f"   ğŸ“Š íš¨ê³¼ í¬ê¸°: {effect_size_interp} (Cohen's d = {cohens_d:.2f})")
print(f"   â†’ Q7 ì ìˆ˜ê°€ ë†’ì€ ì‚¬ëŒì´ êµ¬ë§¤ ì˜í–¥ë„ ë†’ì€ ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.")

# í•˜ë£¨ 2ë²ˆ ìƒ´í‘¸ vs êµ¬ë§¤ ì˜í–¥: Chi-square
contingency_table = pd.crosstab(df['í•˜ë£¨2ë²ˆìƒ´í‘¸'], df['êµ¬ë§¤ì˜í–¥'])
chi2, chi_pvalue, dof, expected = stats.chi2_contingency(contingency_table)

print("\nğŸ“Š í•˜ë£¨2ë²ˆìƒ´í‘¸ vs êµ¬ë§¤ ì˜í–¥ - Chi-square test:")
print("-" * 50)
print(f"   êµì°¨í‘œ:")
print(contingency_table.to_string().replace('\n', '\n   '))
print(f"\n   Chi-square í†µê³„ëŸ‰: {chi2:.4f}")
print(f"   p-value: {chi_pvalue:.4f}")
print(f"   ììœ ë„: {dof}")

# CramÃ©r's V (íš¨ê³¼ í¬ê¸°)
n = contingency_table.sum().sum()
cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))
print(f"   CramÃ©r's V (íš¨ê³¼ í¬ê¸°): {cramers_v:.4f}")

print(f"\nğŸ’¡ í•´ì„:")
if chi_pvalue < 0.05:
    print(f"   âœ… í•˜ë£¨ 2ë²ˆ ìƒ´í‘¸ ì—¬ë¶€ì™€ êµ¬ë§¤ ì˜í–¥ ê°„ì— ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤")
else:
    print(f"   âš ï¸ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤ (p >= 0.05)")

# í•˜ë£¨ 2ë²ˆ ìƒ´í‘¸ ê·¸ë£¹ì˜ êµ¬ë§¤ ì˜í–¥ ë¹„ìœ¨
twice_daily_purchase = df[df['í•˜ë£¨2ë²ˆìƒ´í‘¸'] == 1]['êµ¬ë§¤ì˜í–¥'].mean()
once_daily_purchase = df[df['í•˜ë£¨2ë²ˆìƒ´í‘¸'] == 0]['êµ¬ë§¤ì˜í–¥'].mean()
print(f"   â€¢ í•˜ë£¨ 2ë²ˆ ìƒ´í‘¸ ê·¸ë£¹ êµ¬ë§¤ ì˜í–¥: {twice_daily_purchase:.1%}")
print(f"   â€¢ í•˜ë£¨ 1ë²ˆ ìƒ´í‘¸ ê·¸ë£¹ êµ¬ë§¤ ì˜í–¥: {once_daily_purchase:.1%}")
print(f"   â€¢ ì°¨ì´: +{(twice_daily_purchase - once_daily_purchase)*100:.1f}%p")

# ============================================================
# 5. ê²€ì •ë ¥ ë¶„ì„ (Power Analysis)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Œ 5. ê²€ì •ë ¥(Statistical Power) ë¶„ì„")
print("=" * 70)

print("""
ğŸ“– í•´ì„ ê°€ì´ë“œ:
   ê²€ì •ë ¥ì€ "ì‹¤ì œ íš¨ê³¼ê°€ ìˆì„ ë•Œ ì´ë¥¼ íƒì§€í•  í™•ë¥ "ì…ë‹ˆë‹¤.
   
   â€¢ ê²€ì •ë ¥ â‰¥ 0.80: ì¶©ë¶„í•œ ê²€ì •ë ¥ (ê¶Œì¥)
   â€¢ ê²€ì •ë ¥ < 0.80: ê²€ì •ë ¥ ë¶€ì¡± (Type II ì˜¤ë¥˜ ìœ„í—˜)
   
   í˜„ì¬ ìƒ˜í”Œ ìˆ˜ë¡œ íƒì§€ ê°€ëŠ¥í•œ íš¨ê³¼ í¬ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
""")

# í˜„ì¬ ìƒ˜í”Œ ìˆ˜ë¡œ íƒì§€ ê°€ëŠ¥í•œ ìµœì†Œ íš¨ê³¼ í¬ê¸° (ê·¼ì‚¬ ê³„ì‚°)
n1 = len(q7_purchase_yes)
n2 = len(q7_purchase_no)
alpha = 0.05
power = 0.80

# íš¨ê³¼ í¬ê¸° dì— ëŒ€í•œ ê²€ì •ë ¥ ê³„ì‚° (ê·¼ì‚¬)
from scipy.stats import norm

def calculate_power(n1, n2, d, alpha=0.05):
    """ë‘ í‘œë³¸ t-ê²€ì •ì˜ ê²€ì •ë ¥ ê³„ì‚°"""
    se = np.sqrt(1/n1 + 1/n2)
    z_alpha = norm.ppf(1 - alpha/2)
    z_power = d / se - z_alpha
    return norm.cdf(z_power)

# í˜„ì¬ íš¨ê³¼ í¬ê¸°ì—ì„œì˜ ê²€ì •ë ¥
current_power = calculate_power(n1, n2, abs(cohens_d))

print(f"\nğŸ“Š í˜„ì¬ ë°ì´í„°ì˜ ê²€ì •ë ¥:")
print(f"   â€¢ ìƒ˜í”Œ ìˆ˜: êµ¬ë§¤ì˜í–¥ ìˆìŒ {n1}ëª…, ì—†ìŒ {n2}ëª…")
print(f"   â€¢ ê´€ì¸¡ëœ íš¨ê³¼ í¬ê¸° (Cohen's d): {abs(cohens_d):.4f}")
print(f"   â€¢ í˜„ì¬ ê²€ì •ë ¥: {current_power:.1%}")

if current_power >= 0.80:
    print(f"   âœ… ì¶©ë¶„í•œ ê²€ì •ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤")
else:
    print(f"   âš ï¸ ê²€ì •ë ¥ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ (ê¶Œì¥: 80% ì´ìƒ)")
    
    # 80% ê²€ì •ë ¥ì„ ìœ„í•œ í•„ìš” ìƒ˜í”Œ ìˆ˜ ê³„ì‚° (ê·¼ì‚¬)
    def required_sample_size(d, power=0.80, alpha=0.05):
        z_alpha = norm.ppf(1 - alpha/2)
        z_beta = norm.ppf(power)
        n = 2 * ((z_alpha + z_beta) / d) ** 2
        return int(np.ceil(n))
    
    if abs(cohens_d) > 0.1:
        required_n = required_sample_size(abs(cohens_d))
        print(f"   ğŸ“Š 80% ê²€ì •ë ¥ì„ ìœ„í•œ í•„ìš” ìƒ˜í”Œ ìˆ˜: ê° ê·¸ë£¹ ì•½ {required_n}ëª…")
        print(f"      (í˜„ì¬: {min(n1, n2)}ëª…)")

# ============================================================
# 6. ì¢…í•© ì‹ ë¢°ì„± í‰ê°€
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“Œ 6. ì¢…í•© ì‹ ë¢°ì„± í‰ê°€ ë° ê²°ë¡ ")
print("=" * 70)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Q7(ë‘í”¼ì°¨ì´ì¸ì‹) ì‹ ë¢°ì„± ì¢…í•© í‰ê°€                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚""")

# ê° ê²€ì • ê²°ê³¼ ìš”ì•½
checks = []

# 1. Logistic Regression p-value
if q7_row['p-value'] < 0.05:
    checks.append(("Logistic Regression p-value", "âœ… ìœ ì˜ë¯¸", f"p={q7_row['p-value']:.4f}"))
elif q7_row['p-value'] < 0.1:
    checks.append(("Logistic Regression p-value", "âš ï¸ ê²½ê³„ì„ ", f"p={q7_row['p-value']:.4f}"))
else:
    checks.append(("Logistic Regression p-value", "âŒ ë¹„ìœ ì˜ë¯¸", f"p={q7_row['p-value']:.4f}"))

# 2. Permutation Importance
if q7_perm['ì¤‘ìš”ë„'] - 1.96*q7_perm['í‘œì¤€í¸ì°¨'] > 0:
    checks.append(("Permutation Importance", "âœ… ì•ˆì •ì ", f"CIê°€ 0 ë¯¸í¬í•¨"))
else:
    checks.append(("Permutation Importance", "âš ï¸ ë¶ˆì•ˆì •", f"CIê°€ 0 í¬í•¨"))

# 3. T-test
if t_pvalue < 0.05:
    checks.append(("T-test (ë‹¨ë³€ëŸ‰)", "âœ… ìœ ì˜ë¯¸", f"p={t_pvalue:.4f}"))
elif t_pvalue < 0.1:
    checks.append(("T-test (ë‹¨ë³€ëŸ‰)", "âš ï¸ ê²½ê³„ì„ ", f"p={t_pvalue:.4f}"))
else:
    checks.append(("T-test (ë‹¨ë³€ëŸ‰)", "âŒ ë¹„ìœ ì˜ë¯¸", f"p={t_pvalue:.4f}"))

# 4. íš¨ê³¼ í¬ê¸°
if abs(cohens_d) >= 0.5:
    checks.append(("íš¨ê³¼ í¬ê¸° (Cohen's d)", "âœ… ì¤‘ê°„ ì´ìƒ", f"d={cohens_d:.2f}"))
elif abs(cohens_d) >= 0.2:
    checks.append(("íš¨ê³¼ í¬ê¸° (Cohen's d)", "âš ï¸ ì‘ì€~ì¤‘ê°„", f"d={cohens_d:.2f}"))
else:
    checks.append(("íš¨ê³¼ í¬ê¸° (Cohen's d)", "âŒ ì‘ìŒ", f"d={cohens_d:.2f}"))

# 5. ê²€ì •ë ¥
if current_power >= 0.80:
    checks.append(("ê²€ì •ë ¥", "âœ… ì¶©ë¶„", f"{current_power:.1%}"))
else:
    checks.append(("ê²€ì •ë ¥", "âš ï¸ ë¶€ì¡±", f"{current_power:.1%}"))

for check_name, result, detail in checks:
    print(f"â”‚  â€¢ {check_name:<30} {result:<12} ({detail})  â”‚")

# ì¢…í•© íŒì •
positive_checks = sum(1 for _, result, _ in checks if "âœ…" in result)
total_checks = len(checks)

print(f"""â”‚                                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ“Š ì¢…í•© ì ìˆ˜: {positive_checks}/{total_checks} í•­ëª© í†µê³¼                                      â”‚
â”‚                                                                     â”‚""")

if positive_checks >= 4:
    conclusion = "ë†’ìŒ"
    conclusion_detail = "Q7(ë‘í”¼ì°¨ì´ì¸ì‹)ì´ êµ¬ë§¤ ì˜í–¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ í†µê³„ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
elif positive_checks >= 3:
    conclusion = "ì¤‘ê°„"
    conclusion_detail = "Q7ì˜ ì˜í–¥ì´ ìˆìœ¼ë‚˜, ìƒ˜í”Œ ìˆ˜ ì¦ê°€ë¡œ ë” í™•ì‹¤í•œ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."
else:
    conclusion = "ë‚®ìŒ"
    conclusion_detail = "í˜„ì¬ ë°ì´í„°ë¡œëŠ” Q7ì˜ ì˜í–¥ì„ í™•ì‹ í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì„ ê¶Œì¥í•©ë‹ˆë‹¤."

print(f"""â”‚  ğŸ¯ ì‹ ë¢°ì„± ìˆ˜ì¤€: {conclusion}                                             â”‚
â”‚                                                                     â”‚
â”‚  ğŸ’¡ ê²°ë¡ :                                                            â”‚
â”‚     {conclusion_detail:<60}â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ============================================================
# 7. ê¸°íšì„œìš© ìš”ì•½
# ============================================================
print("=" * 70)
print("ğŸ“Œ 7. ê¸°íšì„œ/ë³´ê³ ì„œìš© ìš”ì•½")
print("=" * 70)

print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ë°ì´ì•¤ë‚˜ì´íŠ¸ ë“€ì–¼ ìƒ´í‘¸ - í†µê³„ ë¶„ì„ ê²°ê³¼ ìš”ì•½              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ“Š ì£¼ìš” ë°œê²¬:                                                       â”‚
â”‚                                                                     â”‚
â”‚  1. Q7(ì•„ì¹¨/ë°¤ ë‘í”¼ ì°¨ì´ ì¸ì‹)ê³¼ êµ¬ë§¤ ì˜í–¥ì˜ ê´€ê³„                     â”‚
â”‚     â€¢ êµ¬ë§¤ ì˜í–¥ ìˆìŒ ê·¸ë£¹ í‰ê· : {q7_purchase_yes.mean():.2f}ì                         â”‚
â”‚     â€¢ êµ¬ë§¤ ì˜í–¥ ì—†ìŒ ê·¸ë£¹ í‰ê· : {q7_purchase_no.mean():.2f}ì                         â”‚
â”‚     â€¢ í†µê³„ì  ìœ ì˜ì„±: p = {t_pvalue:.4f} {'(ìœ ì˜ë¯¸)' if t_pvalue < 0.05 else '(ê²½ê³„ì„ )' if t_pvalue < 0.1 else '(ë¹„ìœ ì˜ë¯¸)'}                      â”‚
â”‚                                                                     â”‚
â”‚  2. í•˜ë£¨ 2ë²ˆ ìƒ´í‘¸ ì‚¬ìš©ìì˜ êµ¬ë§¤ ì˜í–¥                                  â”‚
â”‚     â€¢ í•˜ë£¨ 2ë²ˆ ìƒ´í‘¸ ê·¸ë£¹: {twice_daily_purchase:.1%} êµ¬ë§¤ ì˜í–¥                       â”‚
â”‚     â€¢ í•˜ë£¨ 1ë²ˆ ìƒ´í‘¸ ê·¸ë£¹: {once_daily_purchase:.1%} êµ¬ë§¤ ì˜í–¥                       â”‚
â”‚     â€¢ ì°¨ì´: +{(twice_daily_purchase - once_daily_purchase)*100:.1f}%p                                              â”‚
â”‚                                                                     â”‚
â”‚  3. Feature Importance ìˆœìœ„ (Random Forest ê¸°ì¤€)                     â”‚
â”‚     1ìœ„: Q7(ë‘í”¼ì°¨ì´ì¸ì‹)                                            â”‚
â”‚     2ìœ„: ì—°ë ¹ëŒ€                                                      â”‚
â”‚     3ìœ„: ì´ìœ :ê°€ê²©                                                   â”‚
â”‚     4ìœ„: í•˜ë£¨2ë²ˆìƒ´í‘¸                                                 â”‚
â”‚                                                                     â”‚
â”‚  âœ… í•µì‹¬ ì¸ì‚¬ì´íŠ¸:                                                   â”‚
â”‚     "ì•„ì¹¨ê³¼ ë°¤ ë‘í”¼ ìƒíƒœê°€ ë‹¤ë¥´ë‹¤ê³  ëŠë¼ëŠ” ì†Œë¹„ìì¼ìˆ˜ë¡               â”‚
â”‚      ë°ì´ì•¤ë‚˜ì´íŠ¸ ë“€ì–¼ ìƒ´í‘¸ì— ëŒ€í•œ êµ¬ë§¤ ì˜í–¥ì´ ë†’ë‹¤"                  â”‚
â”‚                                                                     â”‚
â”‚  âš ï¸ ì£¼ì˜ì‚¬í•­:                                                        â”‚
â”‚     â€¢ ìƒ˜í”Œ ìˆ˜ {len(df)}ëª…ìœ¼ë¡œ í†µê³„ì  ê²€ì •ë ¥ì´ ì œí•œì                        â”‚
â”‚     â€¢ ì¶”ê°€ ì„¤ë¬¸ ìˆ˜ì§‘ìœ¼ë¡œ ê²°ê³¼ ê²€ì¦ ê¶Œì¥                               â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ============================================================
# ì‹œê°í™” ìƒì„±
# ============================================================
print("=" * 70)
print("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
print("=" * 70)

# Figure 1: í†µê³„ì  ìœ ì˜ì„± ì‹œê°í™”
fig1, axes = plt.subplots(2, 2, figsize=(14, 12))

# 1-1: Logistic Regression ê³„ìˆ˜ + p-value
ax1 = axes[0, 0]
stats_sorted_by_coef = stats_df.sort_values('ê³„ìˆ˜')
colors = ['#2ecc71' if p < 0.05 else '#f39c12' if p < 0.1 else '#95a5a6' 
          for p in stats_sorted_by_coef['p-value']]
bars = ax1.barh(stats_sorted_by_coef['í”¼ì²˜'], stats_sorted_by_coef['ê³„ìˆ˜'], color=colors, edgecolor='black')
ax1.axvline(x=0, color='black', linestyle='-', linewidth=1)
ax1.set_xlabel('Logistic Regression ê³„ìˆ˜', fontsize=11)
ax1.set_title('ë³€ìˆ˜ë³„ ì˜í–¥ë ¥ ë° í†µê³„ì  ìœ ì˜ì„±\n(ğŸŸ¢ p<0.05  ğŸŸ¡ p<0.1  âšª pâ‰¥0.1)', fontsize=12, fontweight='bold')

# 1-2: Q7 ì ìˆ˜ ë¶„í¬ ë¹„êµ
ax2 = axes[0, 1]
ax2.hist(q7_purchase_yes, bins=5, alpha=0.7, label=f'êµ¬ë§¤ì˜í–¥ ìˆìŒ (n={len(q7_purchase_yes)})', color='#2ecc71', edgecolor='black')
ax2.hist(q7_purchase_no, bins=5, alpha=0.7, label=f'êµ¬ë§¤ì˜í–¥ ì—†ìŒ (n={len(q7_purchase_no)})', color='#e74c3c', edgecolor='black')
ax2.axvline(q7_purchase_yes.mean(), color='#27ae60', linestyle='--', linewidth=2, label=f'ìˆìŒ í‰ê· : {q7_purchase_yes.mean():.2f}')
ax2.axvline(q7_purchase_no.mean(), color='#c0392b', linestyle='--', linewidth=2, label=f'ì—†ìŒ í‰ê· : {q7_purchase_no.mean():.2f}')
ax2.set_xlabel('Q7 ì ìˆ˜ (ì•„ì¹¨/ë°¤ ë‘í”¼ ì°¨ì´ ì¸ì‹)', fontsize=11)
ax2.set_ylabel('ì‘ë‹µì ìˆ˜', fontsize=11)
ax2.set_title(f'Q7 ì ìˆ˜ ë¶„í¬ ë¹„êµ\n(T-test p={t_pvalue:.4f}, Cohen\'s d={cohens_d:.2f})', fontsize=12, fontweight='bold')
ax2.legend(loc='upper left', fontsize=9)

# 1-3: Permutation Importance with CI
ax3 = axes[1, 0]
perm_top10 = perm_df.head(10).sort_values('ì¤‘ìš”ë„')
colors = ['#9b59b6' if (row['ì¤‘ìš”ë„'] - 1.96*row['í‘œì¤€í¸ì°¨']) > 0 else '#bdc3c7' 
          for _, row in perm_top10.iterrows()]
bars = ax3.barh(perm_top10['í”¼ì²˜'], perm_top10['ì¤‘ìš”ë„'], xerr=1.96*perm_top10['í‘œì¤€í¸ì°¨'], 
                color=colors, edgecolor='black', capsize=3)
ax3.axvline(x=0, color='black', linestyle='-', linewidth=1)
ax3.set_xlabel('Permutation Importance (95% CI)', fontsize=11)
ax3.set_title('Permutation Importance\n(ğŸŸ£ CIê°€ 0 ë¯¸í¬í•¨  âšª CIê°€ 0 í¬í•¨)', fontsize=12, fontweight='bold')

# 1-4: Bootstrap ë¶„í¬ (Q7)
ax4 = axes[1, 1]
q7_idx = feature_names_kr.index('Q7(ë‘í”¼ì°¨ì´ì¸ì‹)')
q7_bootstrap = bootstrap_importances[:, q7_idx]
ax4.hist(q7_bootstrap, bins=20, color='#3498db', edgecolor='black', alpha=0.7)
ax4.axvline(q7_bootstrap.mean(), color='red', linestyle='--', linewidth=2, label=f'í‰ê· : {q7_bootstrap.mean():.4f}')
ax4.axvline(np.percentile(q7_bootstrap, 2.5), color='orange', linestyle=':', linewidth=2, label=f'2.5%: {np.percentile(q7_bootstrap, 2.5):.4f}')
ax4.axvline(np.percentile(q7_bootstrap, 97.5), color='orange', linestyle=':', linewidth=2, label=f'97.5%: {np.percentile(q7_bootstrap, 97.5):.4f}')
ax4.set_xlabel('Feature Importance', fontsize=11)
ax4.set_ylabel('ë¹ˆë„', fontsize=11)
ax4.set_title('Q7(ë‘í”¼ì°¨ì´ì¸ì‹) Bootstrap ë¶„í¬\n(n=100 ë°˜ë³µ)', fontsize=12, fontweight='bold')
ax4.legend(loc='upper right', fontsize=9)

plt.suptitle('í†µê³„ì  ì‹ ë¢°ì„± ê²€ì¦ ë¶„ì„', fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('statistical_validation.png', dpi=150, bbox_inches='tight', facecolor='white')
print("   âœ… statistical_validation.png ì €ì¥ ì™„ë£Œ")

# Figure 2: ì‹ ë¢°ì„± ìš”ì•½ ëŒ€ì‹œë³´ë“œ
fig2, ax = plt.subplots(figsize=(12, 8))
ax.axis('off')

# í…ìŠ¤íŠ¸ ìš”ì•½
summary_text = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                    Q7(ë‘í”¼ì°¨ì´ì¸ì‹) í†µê³„ì  ì‹ ë¢°ì„± ê²€ì¦ ê²°ê³¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š ê²€ì • ê²°ê³¼ ìš”ì•½
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ê²€ì • ë°©ë²•                          ê²°ê³¼              ìƒì„¸
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

for check_name, result, detail in checks:
    summary_text += f"  {check_name:<32} {result:<14} {detail}\n"

summary_text += f"""â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“ˆ ì£¼ìš” ìˆ˜ì¹˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ êµ¬ë§¤ì˜í–¥ ìˆìŒ ê·¸ë£¹ Q7 í‰ê· : {q7_purchase_yes.mean():.2f}ì 
  â€¢ êµ¬ë§¤ì˜í–¥ ì—†ìŒ ê·¸ë£¹ Q7 í‰ê· : {q7_purchase_no.mean():.2f}ì 
  â€¢ í‰ê·  ì°¨ì´: {q7_purchase_yes.mean() - q7_purchase_no.mean():.2f}ì 
  â€¢ T-test p-value: {t_pvalue:.4f}
  â€¢ Cohen's d (íš¨ê³¼ í¬ê¸°): {cohens_d:.2f} ({effect_size_interp})
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ¯ ì¢…í•© íŒì •: ì‹ ë¢°ì„± {conclusion}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  {conclusion_detail}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

ax.text(0.5, 0.5, summary_text, transform=ax.transAxes, fontsize=11,
        verticalalignment='center', horizontalalignment='center',
        fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='white', edgecolor='gray'))

plt.savefig('statistical_summary.png', dpi=150, bbox_inches='tight', facecolor='white')
print("   âœ… statistical_summary.png ì €ì¥ ì™„ë£Œ")

print("\n" + "=" * 70)
print("âœ… ë¶„ì„ ì™„ë£Œ!")
print("=" * 70)
print("""
ğŸ“ ìƒì„±ëœ íŒŒì¼:
   1. statistical_validation.png - í†µê³„ì  ì‹ ë¢°ì„± ê²€ì¦ ì‹œê°í™”
   2. statistical_summary.png    - ì‹ ë¢°ì„± ìš”ì•½ ëŒ€ì‹œë³´ë“œ
""")
